{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Homework 1</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Train_set = pd.read_csv('energy_complete/train.csv')\n",
    "Val_set = pd.read_csv('energy_complete/validation.csv')\n",
    "Test_set = pd.read_csv('energy_complete/test.csv')\n",
    "Merge_set = pd.concat([Train_set, Val_set])\n",
    "\n",
    "# Split the dataset\n",
    "cols = [i for i in Train_set.columns if i not in ['date', 'Appliances']]\n",
    "Train_X = Train_set[cols]\n",
    "Train_Y = Train_set['Appliances']\n",
    "Val_X = Val_set[cols]\n",
    "Val_Y = Val_set['Appliances']\n",
    "Test_X = Test_set[cols]\n",
    "Test_Y = Test_set['Appliances']\n",
    "Merge_X = Merge_set[cols]\n",
    "Merge_Y = Merge_set['Appliances']\n",
    "\n",
    "# Define method\n",
    "def getR2(y, pre):\n",
    "    result = r2_score(y, pre)\n",
    "    print('R2:', result)\n",
    "\n",
    "def getRMSE(y, pre):\n",
    "    result =  math.sqrt(mean_squared_error(y, pre))\n",
    "    print('RMSE:', result)\n",
    "\n",
    "def printResult(name, y, pre):\n",
    "    print(name)\n",
    "    getR2(y, pre)\n",
    "    getRMSE(y, pre)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P1A (Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y):\n",
    "    #Train LR model\n",
    "    LR = linear_model.LinearRegression().fit(Train_X, Train_Y)\n",
    "\n",
    "    #Predict the dataset\n",
    "    Train_pre = LR.predict(Train_X)\n",
    "    Val_pre = LR.predict(Val_X)\n",
    "    Test_pre = LR.predict(Test_X)\n",
    "\n",
    "    #Print R2 and RMSE\n",
    "    # print('P1A')\n",
    "    # printResult('Training set', Train_Y,  Train_pre)\n",
    "    # printResult('Validation set', Val_Y,  Val_pre)\n",
    "    # printResult('Test set', Test_Y,  Test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P1B (Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y, Merge_X, Merge_Y):\n",
    "    #Train LR model\n",
    "    LR = linear_model.LinearRegression().fit(Merge_X, Merge_Y)\n",
    "\n",
    "    #Predict the dataset\n",
    "    Train_pre = LR.predict(Train_X)\n",
    "    Val_pre = LR.predict(Val_X)\n",
    "    Test_pre = LR.predict(Test_X)\n",
    "\n",
    "    #Print R2 and RMSE\n",
    "    # print('P1B')\n",
    "    # printResult('Training set', Train_Y,  Train_pre)\n",
    "    # printResult('Validation set', Val_Y,  Val_pre)\n",
    "    # printResult('Test set', Test_Y,  Test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P1C (Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y):\n",
    "    lmbd = [0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 1.0, 10]\n",
    "    for i in lmbd:\n",
    "        # Train Ridge model\n",
    "        RidgeR = linear_model.Ridge(alpha=i).fit(Train_X, Train_Y)\n",
    "\n",
    "        #Predict the dataset\n",
    "        Train_preR = RidgeR.predict(Train_X)\n",
    "        Val_preR = RidgeR.predict(Val_X)\n",
    "        Test_preR = RidgeR.predict(Test_X)\n",
    "\n",
    "        #Print R2 and RMSE\n",
    "        # print('P1C')\n",
    "        # print('lambda:', i)\n",
    "        # printResult('Training set (Ridge)', Train_Y,  Train_preR)\n",
    "        # printResult('Validation set (Ridge)', Val_Y,  Val_preR)\n",
    "        # printResult('Test set (Ridge)', Test_Y,  Test_preR)\n",
    "\n",
    "    for i in lmbd:\n",
    "        # Train Lasso model\n",
    "        LassoR = linear_model.Lasso(alpha=i).fit(Train_X, Train_Y)\n",
    "\n",
    "        #Predict the dataset\n",
    "        Train_preL = LassoR.predict(Train_X)\n",
    "        Val_preL = LassoR.predict(Val_X)\n",
    "        Test_preL = LassoR.predict(Test_X)\n",
    "\n",
    "        #Print R2 and RMSE\n",
    "        # print('lambda:', i)\n",
    "        # printResult('Training set (Lasso)', Train_Y,  Train_preL)\n",
    "        # printResult('Validation set (Lasso)', Val_Y,  Val_preL)\n",
    "        # printResult('Test set (Lasso)', Test_Y,  Test_preL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P1D (Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y, Merge_X, Merge_Y):\n",
    "    Ridge_lmbd = 0.001\n",
    "    # Train Ridge model\n",
    "    RidgeR = linear_model.Ridge(alpha=Ridge_lmbd).fit(Merge_X, Merge_Y)\n",
    "\n",
    "    #Predict the dataset\n",
    "    Train_preR = RidgeR.predict(Train_X)\n",
    "    Val_preR = RidgeR.predict(Val_X)\n",
    "    Test_preR = RidgeR.predict(Test_X)\n",
    "\n",
    "     #Print R2 and RMSE\n",
    "    # print('P1D')\n",
    "    # printResult('Training set (Ridge)', Train_Y,  Train_preR)\n",
    "    # printResult('Validation set (Ridge)', Val_Y,  Val_preR)\n",
    "    # printResult('Test set (Ridge)', Test_Y,  Test_preR)\n",
    "\n",
    "    Lasso_lmbd = 1.0\n",
    "    # Train Lasso model\n",
    "    LassoR = linear_model.Lasso(alpha=Lasso_lmbd).fit(Merge_X, Merge_Y)\n",
    "\n",
    "    #Predict the dataset\n",
    "    Train_preL = LassoR.predict(Train_X)\n",
    "    Val_preL = LassoR.predict(Val_X)\n",
    "    Test_preL = LassoR.predict(Test_X)\n",
    "\n",
    "    #Print R2 and RMSE\n",
    "    # printResult('Training set (Lasso)', Train_Y,  Train_preL)\n",
    "    # printResult('Validation set (Lasso)', Val_Y,  Val_preL)\n",
    "    # printResult('Test set (Lasso)', Test_Y,  Test_preL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y, Merge_X, Merge_Y):\n",
    "    P1A(Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y)\n",
    "    P1B(Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y, Merge_X, Merge_Y)\n",
    "    P1C(Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y)\n",
    "    P1D(Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y, Merge_X, Merge_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catastrophe1313/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.600e+07, tolerance: 1.171e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/catastrophe1313/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.018e+07, tolerance: 1.171e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/catastrophe1313/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.410e+07, tolerance: 1.171e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/catastrophe1313/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+07, tolerance: 1.171e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/catastrophe1313/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+06, tolerance: 1.171e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "LinearRegression(Train_X, Train_Y,  Val_X, Val_Y, Test_X, Test_Y, Merge_X, Merge_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1A\n",
    "#————————————————\n",
    "# Training set\n",
    "# R2: 0.18674709354493313\n",
    "# RMSE: 98.23544703503275\n",
    "# Validation set\n",
    "# R2: 0.0026455735254667934\n",
    "# RMSE: 97.53606522136667\n",
    "# Test set\n",
    "# R2: -0.21195191807869773\n",
    "# RMSE: 100.04127149405939\n",
    "\n",
    "\n",
    "# P1B\n",
    "#————————————————\n",
    "# Training set\n",
    "# R2: 0.16754354896477408\n",
    "# RMSE: 99.38850897378234\n",
    "# Validation set\n",
    "# R2: 0.17512826483284416\n",
    "# RMSE: 88.70205529051167\n",
    "# Test set\n",
    "# R2: 0.09588838543361411\n",
    "# RMSE: 86.40672243517434\n",
    "#————————————————\n",
    "# For training set\n",
    "#   both R2 and RMSE do not have great change, which means these two differnet models perform similarly in predicting training data. \n",
    "# For validation set\n",
    "#   R2 becomes closer to 1 and RMSE reduces, which means the second model performs greater in predicting validation data. \n",
    "# For test set\n",
    "#   R2 changes from negative to positive, which means the correlation between samples and labels changes from negative to positive.And RMSE reduces, which means the second model performs greater in predicting test data. \n",
    "\n",
    "\n",
    "# P1C\n",
    "#————————————————\n",
    "# lambda: 0.001\n",
    "# Training set (Ridge)\n",
    "# R2: 0.18674709354489427\n",
    "# RMSE: 98.2354470350351\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.0026454928035940517\n",
    "# RMSE: 97.53606916845582\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21195209502813417\n",
    "# RMSE: 100.04127879725586\n",
    "\n",
    "# lambda: 0.005\n",
    "# Training set (Ridge)\n",
    "# R2: 0.18674709354396513\n",
    "# RMSE: 98.23544703509123\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.002645169916550616\n",
    "# RMSE: 97.53608495678897\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21195280282616924\n",
    "# RMSE: 100.0413080100484\n",
    "\n",
    "# lambda: 0.01\n",
    "# Training set (Ridge)\n",
    "# R2: 0.18674709354106178\n",
    "# RMSE: 98.23544703526656\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.0026447663088579043\n",
    "# RMSE: 97.53610469214746\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21195368757415345\n",
    "# RMSE: 100.04134452604524\n",
    "\n",
    "# lambda: 0.05\n",
    "# Training set (Ridge)\n",
    "# R2: 0.18674709344819473\n",
    "# RMSE: 98.23544704087543\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.002641537492282575\n",
    "# RMSE: 97.53626257267288\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21196076557398702\n",
    "# RMSE: 100.04163665419885\n",
    "\n",
    "# lambda: 0.1\n",
    "# Training set (Ridge)\n",
    "# R2: 0.18674709315819193\n",
    "# RMSE: 98.2354470583906\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.0026375015855482076\n",
    "# RMSE: 97.53645991739673\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21196961310886886\n",
    "# RMSE: 100.04200181463956\n",
    "\n",
    "# lambda: 0.3\n",
    "# Training set (Ridge)\n",
    "# R2: 0.1867470900718955\n",
    "# RMSE: 98.23544724479247\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.002621359281351765\n",
    "# RMSE: 97.5372492276215\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21200500346573414\n",
    "# RMSE: 100.04346245204391\n",
    "\n",
    "# lambda: 0.5\n",
    "# Training set (Ridge)\n",
    "# R2: 0.1867470839187303\n",
    "# RMSE: 98.23544761642283\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.0026052192321293077\n",
    "# RMSE: 97.53803842119879\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21204039374502948\n",
    "# RMSE: 100.04492306492182\n",
    "\n",
    "# lambda: 1.0\n",
    "# Training set (Ridge)\n",
    "# R2: 0.18674705525003266\n",
    "# RMSE: 98.23544934791514\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.0025648801729060144\n",
    "# RMSE: 97.54001083623544\n",
    "# Test set (Ridge)\n",
    "# R2: -0.21212886542547604\n",
    "# RMSE: 100.04857433801271\n",
    "#————————————————\n",
    "# lambda: 0.001\n",
    "# Training set (Lasso)\n",
    "# R2: 0.18673612166558973\n",
    "# RMSE: 98.23610969718142\n",
    "# Validation set (Lasso)\n",
    "# R2: 0.0004418012287652484\n",
    "# RMSE: 97.64376448349415\n",
    "# Test set (Lasso)\n",
    "# R2: -0.21767483373110164\n",
    "# RMSE: 100.2771940016907\n",
    "\n",
    "# lambda: 0.005\n",
    "# Training set (Lasso)\n",
    "# R2: 0.1867331502350239\n",
    "# RMSE: 98.23628916015781\n",
    "# Validation set (Lasso)\n",
    "# R2: 0.00012563937988596674\n",
    "# RMSE: 97.6592057016141\n",
    "# Test set (Lasso)\n",
    "# R2: -0.2185168126675856\n",
    "# RMSE: 100.31185707123736\n",
    "\n",
    "# lambda: 0.01\n",
    "# Training set (Lasso)\n",
    "# R2: 0.18672881006855602\n",
    "# RMSE: 98.2365512889286\n",
    "# Validation set (Lasso)\n",
    "# R2: -0.00027873107539377884\n",
    "# RMSE: 97.6789514352457\n",
    "# Test set (Lasso)\n",
    "# R2: -0.21959632523880845\n",
    "# RMSE: 100.35628154554283\n",
    "\n",
    "# lambda: 0.05\n",
    "# Training set (Lasso)\n",
    "# R2: 0.1866696039789838\n",
    "# RMSE: 98.24012703111396\n",
    "# Validation set (Lasso)\n",
    "# R2: -0.0038566024202661975\n",
    "# RMSE: 97.85348816896237\n",
    "# Test set (Lasso)\n",
    "# R2: -0.22924880429975492\n",
    "# RMSE: 100.75263309592972\n",
    "\n",
    "# lambda: 0.1\n",
    "# Training set (Lasso)\n",
    "# R2: 0.18655092009559038\n",
    "# RMSE: 98.24729453310341\n",
    "# Validation set (Lasso)\n",
    "# R2: -0.007578094514400835\n",
    "# RMSE: 98.03470135316711\n",
    "# Test set (Lasso)\n",
    "# R2: -0.2370210579362242\n",
    "# RMSE: 101.0706489092436\n",
    "\n",
    "# lambda: 0.3\n",
    "# Training set (Lasso)\n",
    "# R2: 0.18578542520514119\n",
    "# RMSE: 98.29351138834333\n",
    "# Validation set (Lasso)\n",
    "# R2: -0.0240300284894015\n",
    "# RMSE: 98.83182560341535\n",
    "# Test set (Lasso)\n",
    "# R2: -0.27625974926059027\n",
    "# RMSE: 102.66113088084361\n",
    "\n",
    "# lambda: 0.5\n",
    "# Training set (Lasso)\n",
    "# R2: 0.18530686331575985\n",
    "# RMSE: 98.32239358969089\n",
    "# Validation set (Lasso)\n",
    "# R2: -0.026387626464310143\n",
    "# RMSE: 98.94552918085711\n",
    "# Test set (Lasso)\n",
    "# R2: -0.2760187916764538\n",
    "# RMSE: 102.65143922293838\n",
    "\n",
    "# lambda: 1.0\n",
    "# Training set (Lasso)\n",
    "# R2: 0.18399429408516854\n",
    "# RMSE: 98.4015663504163\n",
    "# Validation set (Lasso)\n",
    "# R2: -0.023743971056968016\n",
    "# RMSE: 98.81802056247739\n",
    "# Test set (Lasso)\n",
    "# R2: -0.2570184985609687\n",
    "# RMSE: 101.88431786658941\n",
    "#————————————————\n",
    "#Best lambda for Ridge is 0.001, for Lasso is 1.0\n",
    "\n",
    "\n",
    "#P1D\n",
    "# Training set (Ridge)\n",
    "# R2: 0.16754355125948517\n",
    "# RMSE: 99.38850883679744\n",
    "# Validation set (Ridge)\n",
    "# R2: 0.1751282607547746\n",
    "# RMSE: 88.70205550977796\n",
    "# Test set (Ridge)\n",
    "# R2: 0.09588839354102163\n",
    "# RMSE: 86.40672204775841\n",
    "#————————————————\n",
    "# Training set (Lasso)\n",
    "# R2: 0.16721534362542545\n",
    "# RMSE: 99.40809956300977\n",
    "# Validation set (Lasso)\n",
    "# R2: 0.16693476691014997\n",
    "# RMSE: 89.1415079933204\n",
    "# Test set (Lasso)\n",
    "# R2: 0.10133094250975638\n",
    "# RMSE: 86.14625493005948\n",
    "#————————————————\n",
    "# Ridge model\n",
    "# For training set\n",
    "#   both R2 and RMSE do not have great change, which means these two differnet models perform similarly in predicting training data. \n",
    "# For validation set\n",
    "#   R2 becomes closer to 1 and RMSE reduces, which means the second model performs greater in predicting validation data. \n",
    "# For test set\n",
    "#   R2 changes from negative to positive, which means the correlation between samples and labels changes from negative to positive.And RMSE reduces, which means the second model performs greater in predicting test data. \n",
    "#————————————————\n",
    "# Lasso model\n",
    "# For training set\n",
    "#   both R2 and RMSE do not have great change, which means these two differnet models perform similarly in predicting training data. \n",
    "# For both validation set and test set\n",
    "#   R2 changes from negative to positive, which means the correlation between samples and labels changes from negative to positive. And RMSE reduces, which means the second model performs greater in predicting test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FakeRidgeRegression(Train_X, Train_Y):\n",
    "    # Create augment dataset\n",
    "    Matrix_X = Train_X.values\n",
    "    Matrix_Y = Train_Y.values\n",
    "    lmbd = 0.001\n",
    "    k = 300 # Adding k matrix to train set.\n",
    "    n = Matrix_X.shape[1]\n",
    "    Augment_X = math.sqrt(lmbd)*np.eye(n)\n",
    "    Augment_Y = np.zeros(n)\n",
    "    Agu_X = np.concatenate((Matrix_X, Augment_X))\n",
    "    Agu_Y = np.concatenate((Matrix_Y, Augment_Y))\n",
    "    for i in range(0, k):\n",
    "        Agu_X = np.concatenate((Agu_X, Augment_X))\n",
    "        Agu_Y = np.concatenate((Agu_Y, Augment_Y))\n",
    "\n",
    "    # Train FakeRidge & RealRidge model\n",
    "    Ridge_F = linear_model.LinearRegression().fit(Agu_X, Agu_Y)\n",
    "    Ridge_R = linear_model.Ridge(alpha=lmbd).fit(Train_X, Train_Y)\n",
    "\n",
    "    # Get model coefficients\n",
    "    # print('Fake Coefficients:', Ridge_F.coef_)\n",
    "    # print('Real Coefficients:', Ridge_R.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "FakeRidgeRegression(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P2\n",
    "#————————————————\n",
    "# Fake Coefficients: \n",
    "# [  2.49320482 -12.51326892  11.15077811 -10.61849553 -18.62649245\n",
    "#   22.44435442  15.43933935  -1.55156527  -1.60900395  -0.50453683\n",
    "#   -0.23629734   5.60243886  -0.05221876   0.72200125   0.47643132\n",
    "#    2.55014498  -4.41639317  -0.39755116  -5.52217999 -15.67416736\n",
    "#    0.5338386   -1.91174685   0.25206733   0.234089    14.27473528]\n",
    "#————————————————\n",
    "# Real Coefficients: \n",
    "# [  2.4914212  -12.62973975  11.10982249 -10.53384777 -18.63618682\n",
    "#   22.44679066  15.37017497  -1.43166129  -1.56061632  -0.64121298\n",
    "#   -0.23622164   5.48905784  -0.07221882   1.07943977   0.39871111\n",
    "#    2.46886865  -4.42232377  -1.03332121  -5.39932565 -18.33535979\n",
    "#    0.45170104  -2.4217483    0.12908137   0.23436315  17.18540563]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(Train_X, Train_Y, coef_prior, alpha, maxepochs, samples):\n",
    "    Matrix_X = Train_X.values\n",
    "    Matrix_Y = Train_Y.values\n",
    "    m, n = Matrix_X.shape\n",
    "\n",
    "    # Initial coefficients, lambda\n",
    "    coef = np.zeros((1, n))\n",
    "    lmbd = 0.001\n",
    "    epochs_count = 0\n",
    "\n",
    "    # SGD\n",
    "    while epochs_count < maxepochs:\n",
    "        # Initial gradient\n",
    "        grad = np.zeros((1, n))\n",
    "        # Select random samples\n",
    "        rand = np.random.randint(0, m, samples)\n",
    "        for index in rand:\n",
    "            grad += (-2) * Matrix_X[index] * (Matrix_Y[index]- np.dot(coef, Matrix_X[index])) + lmbd * 2 * (coef - coef_prior)\n",
    "        # Update coefficients\n",
    "        coef = coef - alpha * grad / samples\n",
    "        epochs_count += 1 \n",
    "    return coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegressionWithKnowledge(Train_X, Train_Y):\n",
    "    m, n = Train_X.values.shape\n",
    "\n",
    "    # Initial gradient prior coefficients, learning rate, max epochs, number of samples\n",
    "    coef_prior = np.random.random((1, n))\n",
    "    alpha = 1 / 610000\n",
    "    maxepochs = 100000\n",
    "    samples = 500\n",
    "\n",
    "    # SGD\n",
    "    coef = SGD(Train_X, Train_Y, coef_prior, alpha, maxepochs, samples)\n",
    "    # print('SGD Coefficients:', coef)\n",
    "\n",
    "    # Ridge\n",
    "    Ridge_R = linear_model.Ridge(alpha=0.001).fit(Train_X, Train_Y)\n",
    "    # print('Ridge Coefficients:', Ridge_R.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegressionWithKnowledge(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3\n",
    "#————————————————\n",
    "# SGD Coefficients: \n",
    "# [ 2.56950258 -0.17945565  5.06273598  1.8445301  -4.1366756   2.58180918\n",
    "#    4.50494216 -0.44296763  0.36005156 -0.60120913 -0.30768428  1.7426453\n",
    "#    0.3474155  -0.38734186 -1.4724056   0.42583628 -3.856337   -0.03153693\n",
    "#   -2.05815874  0.07513154  0.15294643 -0.34770901  0.84934323  0.09548237\n",
    "#   -0.1822691 ]\n",
    "#————————————————\n",
    "# Ridge Coefficients: \n",
    "# [  2.4914212  -12.62973975  11.10982249 -10.53384777 -18.63618682\n",
    "#   22.44679066  15.37017497  -1.43166129  -1.56061632  -0.64121298\n",
    "#   -0.23622164   5.48905784  -0.07221882   1.07943977   0.39871111\n",
    "#    2.46886865  -4.42232377  -1.03332121  -5.39932565 -18.33535979\n",
    "#    0.45170104  -2.4217483    0.12908137   0.23436315  17.18540563]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1512f37726af7c68f1d27edf62d97892a0e2e2246e9d7c1943c25041104d8969"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
